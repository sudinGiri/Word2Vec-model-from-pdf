{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pymupdf # This will download and install PyMuPDF, allowing you to import fitz and work with PDF documents in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fitz # fitz is a Python library that is commonly used to interact with PDF documents.\n",
    "import nltk # nltk (Natural Language Toolkit) is a comprehensive library for working with human language data (text) in Python.\n",
    "from nltk.tokenize import sent_tokenize # NLTK library to tokenize text into sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open the PDF file\n",
    "\n",
    "file_path = r\"C:\\\\Users\\\\LENOVO\\Python\\\\THE CONSTITUTION OF INDIA.pdf\" \n",
    "pdf_document = fitz.open(file_path) \n",
    "\n",
    "all_text = \"\"\n",
    "\n",
    "# Extract text from each page and concatenate\n",
    "for page_num in range(len(pdf_document)):\n",
    "    page = pdf_document.load_page(page_num)  # Load the page\n",
    "    text = page.get_text(\"text\")  # Extract text\n",
    "    all_text += text  # Concatenate text from all pages\n",
    "\n",
    "# Close the PDF document\n",
    "pdf_document.close()\n",
    "\n",
    "\n",
    "all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim # Gensim is a Python library for topic modeling, document indexing, and similarity retrieval with large corpora.\n",
    "import pandas as pd # pandas is a powerful and flexible data manipulation and analysis library for Python. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy # spaCy is a powerful and efficient library for advanced Natural Language Processing (NLP) in Python. \n",
    "\n",
    "nltk.download('punkt') # used to download the Punkt tokenizer models, which are used for sentence splitting and word tokenization in the nltk library.\n",
    "nlp = spacy.load(\"en_core_web_sm\") # used to load the small English model in the spaCy library. This model includes features such as tokenization, part-of-speech tagging, named entity recognition, and dependency parsing.\n",
    "sentences = sent_tokenize(all_text) # To tokenize a text into sentences using the sent_tokenize function from the nltk library\n",
    "\n",
    "doc = nlp(all_text) # Trying to process the entire text using spaCy's nlp pipeline\n",
    "\n",
    "all_words = [token.text for token in doc if not token.is_punct and not token.is_space] #extracting all non-punctuation and non-space tokens from the processed text using spaCy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list comprehension to extract lemmas from the processed text while excluding punctuation and space tokens.\n",
    "all_lemmas = [token.lemma_ for token in doc if not token.is_punct and not token.is_space] \n",
    "all_lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a list comprehension to extract non-stop words from the processed text while excluding punctuation and space tokens.\n",
    "non_stop_words = [token.text for token in doc if not token.is_stop and not token.is_punct and not token.is_space] \n",
    "non_stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Define a function to remove punctuation from text\n",
    "def remove_punctuation(text):\n",
    "    # Use list comprehension to remove punctuation from each character in the text\n",
    "    punctuation_free = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return punctuation_free\n",
    "\n",
    "# Apply the remove_punctuation function to each word in the non_stop_words list\n",
    "non_stop_words_punctuation_free = [remove_punctuation(word) for word in non_stop_words if word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop_words_length = len(non_stop_words_punctuation_free)\n",
    "print(f\"\\nShape of non_stop_words without punctuation: {non_stop_words_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts each word to lowercase after removing punctuation.\n",
    "non_stop_words_punctuation_free = [remove_punctuation(word).lower() for word in non_stop_words if word] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To findout the unique words from non_stop_words_punctuation_free\n",
    "\n",
    "seen = set()  # Create an empty set to keep track of seen words\n",
    "non_stop_words_unique = []  # Create an empty list to store unique words\n",
    "\n",
    "# Iterate over each word in the list non_stop_words_punctuation_free\n",
    "for word in non_stop_words_punctuation_free:\n",
    "    if word not in seen:  # Check if the word has not been seen before\n",
    "        seen.add(word)  # Add the word to the set of seen words\n",
    "        non_stop_words_unique.append(word)  # Add the word to the list of unique words\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_stop_words_punctuation_free"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec as wv\n",
    "\n",
    "# Define the list of sentences for Word2Vec training\n",
    "sentences_for_word2vec = [non_stop_words_punctuation_free]\n",
    "\n",
    "# Train the Word2Vec model\n",
    "model = wv(\n",
    "    sentences=sentences_for_word2vec,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "model.save(\"THE CONSTITUTION OF INDIA_W2V.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most similar words\n",
    "model.wv.most_similar('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between two words\n",
    "model.wv.similarity('india','state')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FastText Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import FastText # to use FastText to train a model and find similar words. FastText, another popular word embedding model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define the list of sentences for Fasttext training\n",
    "sentences_for_fasttext = [non_stop_words_punctuation_free]\n",
    "\n",
    "# Train FastText model\n",
    "model = FastText(\n",
    "    sentences = sentences_for_fasttext,\n",
    "    vector_size=100,\n",
    "    window=5,\n",
    "    min_count=2,\n",
    "    workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save(\"THE CONSTITUTION OF INDIA_FastText.model\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most similar words\n",
    "model.wv.most_similar('state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity between two words\n",
    "model.wv.similarity('india','state')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
